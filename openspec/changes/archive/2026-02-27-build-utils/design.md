## Context

`src/utils.py` is a zero-dependency helper module — it imports nothing from the project and requires no external libraries beyond Python's standard library. It must be implemented before `src/generator.py`, which calls `estimate_cost()` to track API usage costs.

## Goals / Non-Goals

**Goals:**
- Define a `PRICING` module-level dict constant mapping model IDs to per-million-token input/output rates
- Implement `estimate_cost(input_tokens: int, output_tokens: int, model: str) -> float` — compute USD cost from token counts
- Implement `format_cost(cost: float) -> str` — render a cost float as `"$X.XXXX"` (always 4 decimal places)
- Implement `sanitize_anchor(text: str) -> str` — convert heading text to a valid Markdown anchor slug
- Implement `create_progress_bar(current: int, total: int) -> str` — return a progress string like `"[3/12] Generating..."`

**Non-Goals:**
- Runtime pricing updates (no API calls to fetch current rates)
- Locale-aware cost formatting
- External token counting libraries (tiktoken, etc.)
- Persistent logging or state

## Decisions

**Pricing table as a module-level `PRICING` dict constant**
Centralising rates in one named constant makes future price updates a one-line change and keeps the logic in `estimate_cost()` simple. Scattering magic numbers across the codebase would make rate changes error-prone.

**`estimate_cost()` raises `ValueError` for unknown models**
Silently returning 0 or a default rate would hide configuration mistakes. Failing fast with a clear message (`"Unknown model: ..."`) surfaces the problem immediately.

**`format_cost()` always produces 4 decimal places**
`f"${cost:.4f}"` is locale-independent, requires no external library, and gives sufficient precision for sub-cent costs typical in LLM usage.

**`sanitize_anchor()` lowercases, replaces spaces with `-`, strips non-alphanumeric/hyphen characters**
This matches the GitHub-Flavored Markdown anchor convention used by most Markdown renderers and is the simplest correct behaviour for the heading texts generated by the LLM.

**`create_progress_bar()` returns a plain `[current/total] Generating...` string**
A simple counter string is sufficient for CLI progress feedback and requires no terminal control codes or external libraries.

## Risks / Trade-offs

- **Pricing table goes stale** as Anthropic adjusts rates → Mitigated by keeping all rates in one constant (`PRICING` in `utils.py`) so updates are a single-file change
- **`estimate_cost()` raises on unknown models** → callers must pass a valid model ID; this is the correct tradeoff for a tool that is always called with a known configured model

## Open Questions

*(none)*
